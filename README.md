WIP | LLM - local approach

Need llhama to execute the models.
Install llhama and pull the model.
Uses uv to run the scripts for while.
